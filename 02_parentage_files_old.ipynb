{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = open('/home/lindb/pythonimports.py').read()\n",
    "exec(imp)\n",
    "from __future__ import division\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get genotype data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get first round genotyping\n",
    "geno = pd.read_csv('/home/lindb/teakettle/genemarker/results.tsv',header=0,index_col=None,sep='\\t')\n",
    "cols = [col for col in sorted(geno.columns) if 'samp' not in col]\n",
    "geno = geno[['samp']+cols]\n",
    "geno.replace(np.nan,\"NA\",inplace=True)\n",
    "#geno = geno.loc[np.where(geno['samp']!='NA')[0].tolist(),:]\n",
    "geno.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make sure the second allele is there\n",
    "nucs = ['rps2','rps39','rps50','rps12']\n",
    "for row in geno.index:\n",
    "    for nuc in nucs:\n",
    "        if geno.loc[row,\"%s_2\" % nuc] == \"NA\" and geno.loc[row,nuc] != \"NA\":\n",
    "            print 'homogenizing %s\\'s %s' % (geno.loc[row,'samp'],nuc)\n",
    "            geno.loc[row,\"%s_2\" % nuc] = geno.loc[row,nuc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geno.to_csv('/home/lindb/teakettle/data/geno.txt',index=False,sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(geno.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get second round genotyping\n",
    "filE = '/home/lindb/teakettle/genemarker/results_round_2.tsv'\n",
    "geno2 = pd.read_csv(filE,index_col=None,sep='\\t')\n",
    "geno2 = geno2[['samp']+cols]\n",
    "geno2.replace(np.nan,\"NA\",inplace=True)\n",
    "geno2 = geno2.loc[np.where(geno2['samp']!='NA')[0].tolist(),:]\n",
    "geno2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make sure the second alleles are there for homozygotes\n",
    "nucs = ['rps2','rps39','rps50','rps12']\n",
    "for row in geno2.index:\n",
    "    for nuc in nucs:\n",
    "        if geno2.loc[row,\"%s_2\" % nuc] == \"NA\" and geno2.loc[row,nuc] != \"NA\":\n",
    "            print 'homogenizing %s\\'s %s' % (geno2.loc[row,'samp'],nuc)\n",
    "            geno2.loc[row,\"%s_2\" % nuc] = geno2.loc[row,nuc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geno2.to_csv('/home/lindb/teakettle/data/geno2.txt',header=True,index=False,sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(geno2.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samps = uni(geno2['samp'].tolist() + geno['samp'].tolist())\n",
    "samps = [samp for samp in samps if samp != 'NA']\n",
    "len(samps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a blank df to put in values\n",
    "dsamps = sorted(samps + samps)\n",
    "g = pd.DataFrame(index=dsamps,columns=geno2.columns)\n",
    "g['samp'] = g.index.tolist()\n",
    "g.index = np.arange(len(g.index))\n",
    "g.replace(np.nan,'NA',inplace=True)\n",
    "g.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in blank df\n",
    "dfs = [geno,geno2]\n",
    "for i,df in enumerate(dfs):\n",
    "    for row in df.index:\n",
    "        w = np.where(g['samp']==df.loc[row,'samp'])[0].tolist()\n",
    "        for col in df.columns[1:]:\n",
    "            if not g.loc[w[i],col] == \"NA\": #overwriting is bad, mkay\n",
    "                print 'crap'\n",
    "            else:\n",
    "                if not df.loc[row,col] == \"NA\":\n",
    "                    g.loc[w[i],col] = int(np.round(df.loc[row,col]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.replace(\"NA\",0,inplace=True)\n",
    "g.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filE = '/home/lindb/teakettle/data/full_geno.txt'\n",
    "g.to_csv(filE,header=True,index=False,sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filE = '/home/lindb/teakettle/data/full_geno.txt'\n",
    "g = pd.read_csv(filE, header=0,index_col=None,sep='\\t')\n",
    "g.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loci = sorted(nucs + ['pc10','pt71936','pt87268'])\n",
    "loci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look at missing data\n",
    "c = Counter()\n",
    "x = \"\"\n",
    "for samp in uni(g['samp']):\n",
    "    df = g.loc[np.where(g['samp']==samp)[0].tolist(),:]\n",
    "    assert luni(df['samp']) == 1\n",
    "    i,j = (df.index[0],df.index[1])\n",
    "    miss = df.loc[i,loci].tolist().count(0)\n",
    "    if miss == 0:\n",
    "        c[str(miss)] += 1\n",
    "    else:\n",
    "        for l in loci:\n",
    "            if df.loc[i,l] == 0:\n",
    "                if not df.loc[j,l] == 0:\n",
    "                    miss = miss - 1\n",
    "#                     x = 'break'\n",
    "        c[str(miss)] += 1\n",
    "#     if x == 'break':\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "68+22+116+90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "296/96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blanks = [samp for samp in g['samp'] if 'blank' in samp]\n",
    "b = g.loc[[np.where(g['samp'] == x)[0].tolist()[0] for x in g['samp'].tolist() if x in blanks],:]\n",
    "b.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "luni(g.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.index[1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get tree location data from master data, add X Y to geno df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get tree location data from master data, add X Y to geno df\n",
    "t = pd.read_csv('/home/lindb/teakettle/data/trees.txt',sep='\\t',index_col=None)\n",
    "t.replace(\"TRUE\",True,inplace=True)\n",
    "t.replace(\"FALSE\",False,inplace=True)\n",
    "t.replace('True',True,inplace=True)\n",
    "t.replace('False',False,inplace=True)\n",
    "t = t.loc[t['sampled'] != False,:]\n",
    "t.index = np.arange(len(t.index))\n",
    "t.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(s):\n",
    "    num,plot = (s[:-3],s[-3:])\n",
    "    if 'new' in num:\n",
    "        num,new = (num[:-3],num[-3:])\n",
    "        while len(num) < 3:\n",
    "            num = '0%s' % num\n",
    "    else:\n",
    "        new = \"\"\n",
    "    samp = \"%s_%s%s\" % (plot,new,num)\n",
    "    return(samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert sample name to convention in genotype data\n",
    "t['converted'] = t['COMBO'].apply(lambda x: convert(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = ['converted','seedling','x','y','z','xutm','yutm','zutm','dbh_11','dbh_04','dbh_13']\n",
    "info = t.loc[:,grid]\n",
    "info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make sure either True or MD (missing data)\n",
    "uni(t['sampled'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fix a few sample names in g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msamps = []\n",
    "for s in uni(g['samp']):\n",
    "    if not s in t['converted'].tolist():\n",
    "        if not 'blank' in s:\n",
    "            msamps.append(s)\n",
    "            print s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(msamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(g.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert names if necessary, keep track of weird samps (may have forgotten to put sampled = True in t.DataFrame)\n",
    "skips = []\n",
    "count = 0\n",
    "track = []\n",
    "changed = []\n",
    "for row in g.index:\n",
    "    sold = \"\"\n",
    "    s = g.loc[row,'samp']\n",
    "    count += 1\n",
    "    if s in msamps:\n",
    "        sold = s\n",
    "        if 'new' in s:\n",
    "            while s not in t['converted'].tolist():\n",
    "                plt_new,num = (s[:7],s[7:])\n",
    "                s = \"\".join([plt_new,\"0%s\" % num])\n",
    "                if s in t['converted'].tolist():\n",
    "                    print \"converted %s to %s\" % (sold,s)\n",
    "                    changed.append(sold)\n",
    "                    g.loc[row,'samp'] = s\n",
    "        elif '0' in s:\n",
    "            plot,num = s.split(\"_\")\n",
    "            if not num.startswith(\"0\"):\n",
    "                print \"skipped %s\" % sold\n",
    "                skips.append(sold)\n",
    "                continue\n",
    "            while s not in t['converted'].tolist():\n",
    "                num = num[1:]\n",
    "                s = \"_\".join([plot,num])\n",
    "                if s in t['converted'].tolist():\n",
    "                    print \"found %s to be %s\" % (sold,s)\n",
    "                    changed.append(sold)\n",
    "                    g.loc[row,'samp'] = s\n",
    "        else:\n",
    "            print \"skipped %s\" % sold\n",
    "            skips.append(sold)\n",
    "    track.append(s)\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make sure I'm not screwing something up\n",
    "for row in g.index:\n",
    "    s = g.loc[row,'samp']\n",
    "    if s in msamps:\n",
    "        if s not in changed:\n",
    "            if s not in skips:\n",
    "                print \"dammit %s!\" % s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni(skips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni(skips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['bc3_3980', #sampled = F\n",
    " 'uc2_3141',    #not in plot data\n",
    " 'uc2_5185',    #not in plot data\n",
    " 'uc2_9554',    #not in plot data \n",
    " 'uc2_9592',    #not in plot data \n",
    " 'uc2_9920', #change to 9220 in g\n",
    " 'un1_2749',    #not in plot data\n",
    " 'un2_3126',    #not in data\n",
    " 'un3_1542', #sampled = F\n",
    " 'un3_2588',    #not in data\n",
    " 'us3_1087', #marked as abco in data\n",
    " 'us3_1752']    #not in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix = ['bc3_3980',\n",
    "       'uc2_9920',\n",
    "       'un1_2749',\n",
    "       'un2_3126',\n",
    "       'un3_1542',\n",
    "       'us3_1087',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fix errors and redo above (leaving the fix scripts here)\n",
    "tree = pd.read_csv('/home/lindb/teakettle/data/trees.txt',sep='\\t',index_col=0)\n",
    "tree.index = np.arange(len(tree.index))\n",
    "tree['converted'] = tree['COMBO'].apply(lambda x: convert(x))\n",
    "tree.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(tree['converted'] == 'bc3_3980')[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.loc[6285,['COMBO','converted','sampled']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.loc[6285,'sampled'] = 'True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(g['samp'] == 'uc2_9920')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.loc[602,'samp'] = 'uc2_9220' \n",
    "g.loc[603,'samp'] = 'uc2_9220' #I saved g to overwrite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(tree['converted'] == 'un3_1542')[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.loc[32670,['species','converted','sampled']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.loc[32670,'sampled'] = 'True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(tree['converted'] == 'us3_1087')[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.loc[38760,['species','converted','sampled']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.loc[38760,['species']] = 'pila'\n",
    "tree.loc[38760,['sampled']] = 'True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filE = '/home/lindb/teakettle/data/trees.txt'\n",
    "tree.to_csv(filE,header=True,index=False,sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# combine dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g.index = g['samp']\n",
    "g.index = g['samp'].tolist()\n",
    "g.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info.index = info['converted']\n",
    "info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info.loc[info.index[0],'dbh_04']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in info.index:\n",
    "    if info.loc[row,'seedling'] == False:\n",
    "        if math.isnan(info.loc[row,'dbh_11']):\n",
    "            if math.isnan(info.loc[row,'dbh_04']) == False:\n",
    "                info.loc[row,'dbh_11'] = info.loc[row,'dbh_04']*0.9699+5.1995 #lm(dbh_11 ~ dbh_04)\n",
    "            else:\n",
    "                info.loc[row,'dbh_11'] = 28.37125 #(median + mean)/2  -- 6 trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(info['dbh_11'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = pd.merge(g,info,left_index=True,right_index=True)\n",
    "c.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccols = ['samp',\n",
    " 'x',\n",
    " 'y',\n",
    " 'dbh_11',\n",
    " 'xutm',\n",
    " 'yutm',\n",
    " 'seedling',\n",
    " 'rps12',\n",
    " 'rps12_2',\n",
    " 'rps2',\n",
    " 'rps2_2',\n",
    " 'rps39',\n",
    " 'rps39_2',\n",
    " 'rps50',\n",
    " 'rps50_2',\n",
    " 'pc10',\n",
    " 'pt71936',\n",
    " 'pt87268']\n",
    "c = c[ccols]\n",
    "c.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.loc['bc1_new007','dbh_11']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(c.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.index = np.arange(len(c.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.loc[row,'seedling']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.replace(np.nan,'NA',inplace=True)\n",
    "DIR = '/home/lindb/teakettle/data/moran'\n",
    "if not op.exists(DIR):\n",
    "    os.makedirs(DIR)\n",
    "c.to_csv(op.join(DIR,'all_data.txt'),header=True,index=False,sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(c.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(g.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(uni(g['samp'])) - set(info['converted']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2610-2552 == 29*2 #difference in index length is due to blanks and samps not in plot data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots = []\n",
    "for row in c.index:\n",
    "    plot = c.loc[row,'samp'][0].split(\"_\")[0]\n",
    "    if not plot in plots:\n",
    "        plots.append(plot)\n",
    "len(plots),plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.loc[row,'samp'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# to do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. compare vals to dyer's machine\n",
    "1. make sure no name samples aren't from bleedthrough\n",
    "1. remove \"\" samples and 'blank's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = sorted(ls('/home/lindb/teakettle/data/moran/amat_files2/'))\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = sorted(ls('/home/lindb/teakettle/data/moran/amat_files2/'),reverse=True)\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = sorted(ls('/home/lindb/teakettle/data/moran/amat_files2/'),reverse=True)\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for k in np.arange(558):\n",
    "    i = k+1\n",
    "    for q in np.arange(558):\n",
    "        count += 1\n",
    "        if count % 1000 == 0:\n",
    "            print count\n",
    "        j = q+1\n",
    "        text = '''\n",
    "source('/home/lindb/imports.R')\n",
    "\n",
    "#load dependencies\n",
    "dname = '/home/lindb/teakettle/data/moran/dependencies/'\n",
    "files = c()\n",
    "for (f in list.files(dname)){\n",
    "    if (endsWith(f,'RDS'))\n",
    "    {\n",
    "        #cat(sprintf (\"loading %%s file\",f))\n",
    "        fname = paste(dname,f,sep=\"\")\n",
    "        obj = strsplit(f,split='.RDS')[[1]]\n",
    "        assign(obj,readRDS(fname))    \n",
    "    }\n",
    "}\n",
    "\n",
    "amat <- numeric(0)\n",
    "for (k in 1:noff)\n",
    "{\n",
    "    a <- matrix(0,(nadult+1),(nadult+1)) \n",
    "    amat <- append(amat,list(a))\n",
    "}\n",
    "    \n",
    "i <- %s\n",
    "j <- %s\n",
    "#print (\"i=\")\n",
    "#print(i)\n",
    "#print(\"j=\")\n",
    "#print(j)\n",
    "\n",
    "\n",
    "if(i>0) #we want it to run no matter what\n",
    "{\n",
    "    print (\"starting loop\")\n",
    "    if(i==j & i<(nadult+1)) #this is the diagonal, can't have same sampled mother and father\n",
    "    {\n",
    "        unimportant = 1+1 # amat is already 0 on the diagonal, save some time by not looping\n",
    "#         for (k in 1:noff)\n",
    "#         {\n",
    "#             amat[[k]][i,j] <- 0   \n",
    "#         }\n",
    "    }\n",
    "    if(i==j & i==(nadult+1)) #can have two out-of-plot parents\n",
    "    { \n",
    "        nmat <- numeric(0)\n",
    "        pg1 <- pgout \n",
    "        pg1.b <- pgout \n",
    "        pg2 <- pgout \n",
    "        pg2.b <- pgout\n",
    "        #print (\"starting loci loop\")\n",
    "        for(la in 1:nloci) \n",
    "        {#Calculate probability of offspring genotype given parental genotypes using global allele frequencies\n",
    "            #at the la'th locus\n",
    "            #print (la)\n",
    "            nm <- nmat.func(pg1,pg2,pg1.b,pg2.b,la) #returns a matrix with ncol = nrow = nallele @ la'th locus\n",
    "            nmat <- append(nmat,list(nm))\n",
    "        }\n",
    "        #print (\"starting offspring loop\")\n",
    "        for(k in 1:noff)\n",
    "        {\n",
    "            #print (k)\n",
    "            pq <- 1 #incorrectly overwriting pq is bad, mkay\n",
    "            og <- rbind(goff[[1]][k,],goff[[2]][k,]) #get the offspring's observed first and second alleles\n",
    "            og.b <- rbind(goff.r[[1]][k,],goff.r[[2]][k,]) #get any offspring's observed regenotyping results\n",
    "            #print (\"starting loci loop\")\n",
    "            for(la in 1:nloci)\n",
    "            {\n",
    "                #print (la)\n",
    "                #om = probability of observing the given offspring genotype given all possible true genotypes\n",
    "                om <- omat.func(og,og.b,la) \n",
    "            #pq = probability of observing the given offspring genotype given the observed parental genotypes\n",
    "                pq <- pq*sum(nmat[[la]]*om)\n",
    "                #if the posited parents are not the parents, no use in doing futher calculations @ other loci\n",
    "                if(pq==0) \n",
    "                {\n",
    "                    break \n",
    "                }\n",
    "            }\n",
    "            #print (\"writing amat\")\n",
    "            amat[[k]][i,j] <- pq #pq same as above, for the k'th offspring for the i'th and j'th parent\n",
    "            amat[[k]][j,i] <- pq \n",
    "        }# end offspring loop\n",
    "    }# end two-out-of-plot loop\n",
    "    if(i!=j) #if not on the diagonal\n",
    "    { #all other combos... \n",
    "        nmat <- numeric(0)\n",
    "        if(i<(nadult+1)) #if posited parent one of those who were sampled\n",
    "        {\n",
    "            #gadult# == nrow=nadult ncol=nloci\n",
    "            pg1 <- rbind(gadult[[1]][i,],gadult[[2]][i,])  #get first and second alleles for all loci\n",
    "            pg1.b <- rbind(gadult.r[[1]][i,],gadult.r[[2]][i,]) #get first and second alleles for regenotyping\n",
    "        } \n",
    "        if(j<(nadult+1)) #if posited parent one of those who were sampled\n",
    "        {\n",
    "            pg2 <- rbind(gadultF[[1]][j,],gadultF[[2]][j,])\n",
    "            pg2.b <- rbind(gadultF.r[[1]][j,],gadultF.r[[2]][j,]) \n",
    "        }\n",
    "        if(i==(nadult+1)) #if posited parent is not one of those who were sampled\n",
    "        { \n",
    "            pg1 <- pgout \n",
    "            pg1.b <- pgout\n",
    "        } \n",
    "        if(j==(nadult+1)) #if posited parent is not one of those who were sampled\n",
    "        {\n",
    "            pg2 <- pgout #put in all zeros\n",
    "            pg2.b <- pgout #put in all zeros\n",
    "        }\n",
    "        #print (\"starting loci loop\")\n",
    "        for(la in 1:nloci)\n",
    "        {#Calculate probability of offspring genotype given parental genotypes using global allele frequencies\n",
    "            #at the la'th locus\n",
    "            print (la)\n",
    "            nm <- nmat.func(pg1,pg2,pg1.b,pg2.b,la) \n",
    "            nmat <- append(nmat,list(nm))\n",
    "        }\n",
    "        #print (\"starting offspring loop\")\n",
    "        for(k in 1:noff)\n",
    "        { #pre-calc nmat at all loci for parent pair\n",
    "            #print(k)\n",
    "            pq <- 1 #incorrectly overwriting is still bad, mkay\n",
    "            og <- rbind(goff[[1]][k,],goff[[2]][k,]) #get the k'th offspring's 1st and 2nd alleles @ all loci\n",
    "            og.b <- rbind(goff.r[[1]][k,],goff.r[[2]][k,])\n",
    "            #print (\"starting loci loop\")\n",
    "            for(la in 1:nloci)\n",
    "            {\n",
    "                print (la)\n",
    "                #om = probability of observing the given offspring genotype given all possible true genotypes\n",
    "                om <- omat.func(og,og.b,la)\n",
    "                #pq = probability of observing the given offspring genotype given the observed parental genotypes\n",
    "                pq <- pq*sum(nmat[[la]]*om)\n",
    "                if(pq==0) \n",
    "                {\n",
    "                #if the posited parents are not the parents, no use in doing futher calculations @ other loci\n",
    "                    break \n",
    "                }\n",
    "            }\n",
    "            amat[[k]][i,j] <- pq \n",
    "            amat[[k]][j,i] <- pq \n",
    "        }# end offspring loop\n",
    "    }#end \"all other combos\" loop\n",
    "    \n",
    "#     track[i,j] <- 1\n",
    "#     track[j,i] <- 1\n",
    "\n",
    "} \n",
    "\n",
    "#print (\"writing RDS files\")\n",
    "DIR = '/home/lindb/teakettle/data/amat_outfiles/'\n",
    "amatfname = paste(DIR,'amat_%s_%s.RDS',sep=\"\")\n",
    "nmatfname = paste(DIR,'nmat_%s_%s.RDS',sep=\"\")\n",
    "#sprintf(\"writing %%s\",amatfname)\n",
    "saveRDS(amat,amatfname)\n",
    "#sprintf(\"writing %%s\",nmatfname)\n",
    "saveRDS(nmat,nmatfname)\n",
    "\n",
    "''' % (i,\n",
    "       j,\n",
    "       str(i).zfill(3),\n",
    "       str(j).zfill(3),\n",
    "       str(i).zfill(3),\n",
    "       str(j).zfill(3)\n",
    "      )\n",
    "        DIR = '/home/lindb/teakettle/data/moran/amat_files2'\n",
    "        if not op.exists(DIR):\n",
    "            os.makedirs(DIR)\n",
    "        filE = op.join(DIR,\"amat_%s_%s.R\" % (str(i).zfill(3),str(j).zfill(3)))\n",
    "        with open(filE,'wb') as o:\n",
    "            o.write(\"%s\" % text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# at some point go back and compare Dyer's machine to Cornell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
